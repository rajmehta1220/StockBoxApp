{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "apwc4U3eneaG"
      },
      "outputs": [],
      "source": [
        "import pandas_datareader as web\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import os\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from datetime import date\n",
        "\n",
        "def temp_func(key):\n",
        "    today = date.today()\n",
        "    d1 = today.strftime(\"%m/%d/%Y\")\n",
        "\n",
        "\n",
        "    data= web.DataReader(key, data_source='yahoo', start='01/22/1999', end=d1)\n",
        "    print(data)\n",
        "    dataset = data['Adj Close'].values\n",
        "\n",
        "    dataset = dataset.reshape(-1,1)\n",
        "\n",
        "\n",
        "    dataset_train = np.array(dataset[:int(dataset.shape[0]*0.8)])\n",
        "    training_dataset_length = math.ceil(len(dataset) * .8)\n",
        "    dataset_test = np.array(dataset[int(dataset.shape[0]*0.8):])\n",
        "\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0,1))\n",
        "    dataset_train = scaler.fit_transform(dataset_train)\n",
        "    dataset_test = scaler.fit_transform(dataset_test)\n",
        "\n",
        "    look_back = 1 \n",
        "    def create_dataset(dataset):\n",
        "        x, y = [],[]\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:i+look_back, 0]\n",
        "            x.append(a)\n",
        "            y.append(dataset[i+look_back+1, 0])\n",
        "\n",
        "        dataX = np.array(x)\n",
        "        dataY = np.array(y)\n",
        "        return dataX, dataY\n",
        "\n",
        "    # reshape into X=t and Y=t+1\n",
        "    trainX, trainY = create_dataset(dataset_train)\n",
        "    testX, testY = create_dataset(dataset_test)\n",
        "\n",
        "\n",
        "    # reshape input to be [samples, time steps, features]\n",
        "    trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
        "    testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
        "\n",
        "    # create and fit the LSTM network\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(4, input_shape=(1, 1)))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    model.fit(trainX, trainY, epochs=10, batch_size=10, verbose=2)\n",
        "\n",
        "    predictions = model.predict(testX)\n",
        "\n",
        "    mse = np.mean((predictions-testX)**2)\n",
        "    print(\"MeanSquaredError is :\", mse)\n",
        "\n",
        "    predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "    y_test_scaled = scaler.inverse_transform(testY.reshape(-1,1))\n",
        "    print(\"\\n Predicted Value:\", predictions[-1])\n",
        "    temp_variable = predictions[-1].tolist()\n",
        "\n",
        "    return temp_variable[0]\n"
      ]
    }
  ]
}